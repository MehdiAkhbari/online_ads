{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\utils\\_clustering.py:35: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n",
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\utils\\_clustering.py:54: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n",
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\utils\\_clustering.py:63: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window(order, start, length):\n",
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\utils\\_clustering.py:69: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window_score_gain(masks, order, start, length):\n",
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\utils\\_clustering.py:77: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _mask_delta_score(m1, m2):\n",
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\links.py:5: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def identity(x):\n",
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\links.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _identity_inverse(x):\n",
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\links.py:15: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def logit(x):\n",
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\links.py:20: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _logit_inverse(x):\n",
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\utils\\_masked_model.py:363: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\utils\\_masked_model.py:385: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\utils\\_masked_model.py:428: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n",
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\utils\\_masked_model.py:439: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n",
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\maskers\\_tabular.py:186: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n",
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\maskers\\_tabular.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n",
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\maskers\\_image.py:175: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n",
      "c:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\shap\\explainers\\_partition.py:676: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def lower_credit(i, value, M, values, clustering):\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank 20 model loaded!\n",
      "rank 40 model loaded!\n",
      "rank 60 model loaded!\n",
      "rank 80 model loaded!\n",
      "rank 100 model loaded!\n",
      "rank 20 model loaded!\n",
      "rank 40 model loaded!\n",
      "rank 60 model loaded!\n",
      "rank 80 model loaded!\n",
      "rank 100 model loaded!\n",
      "rank 20 model loaded!\n",
      "rank 40 model loaded!\n",
      "rank 60 model loaded!\n",
      "rank 80 model loaded!\n",
      "rank 100 model loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from econml.dml import CausalForestDML\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.linear_model import Lasso, LassoCV, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "from econml.sklearn_extensions.model_selection import GridSearchCVList\n",
    "import time\n",
    "import joblib\n",
    "import multiprocessing\n",
    "import pickle\n",
    "\n",
    "\n",
    "import config\n",
    "from utils import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# For ignoring the warnings\n",
    "from warnings import simplefilter, filterwarnings\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "filterwarnings(\"ignore\", category=UserWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "\n",
    "base_ad = 50\n",
    "max_adv_rank = 100\n",
    "max_visit_no = 100 # max number of page visits by each user\n",
    "\n",
    "# read data\n",
    "data = pd.read_stata(\"..\\\\data\\\\Simulation Data - Last 2 Days - Aggregate.dta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chunk the data\n",
    "chunk_users_num = 400000\n",
    "n_chunks = int(data.global_token_new.max() / chunk_users_num) + 1\n",
    "data['chunk'] = ((data['global_token_new'] / chunk_users_num).astype(int) + 1)\n",
    "data_chunks = []\n",
    "\n",
    "for chunk in range(1, n_chunks + 1):\n",
    "        var_name = f\"data_chunk_{chunk}\"\n",
    "        globals()[var_name] = data[data['chunk'] == chunk]\n",
    "        exec(f\"data_chunks.append(data_chunk_{chunk})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_duopoly(data):\n",
    "    # file_name = f\"data_chunk_{chunk}\"\n",
    "    # create empty columns in the dataframe to fill later\n",
    "    create_chosen_split_ad_vars(data)\n",
    "\n",
    "    \n",
    "    # print(f\"\\n\\n\\n=======> Chunk #{chunk}\")\n",
    "    start_time_2 = time.perf_counter()\n",
    "\n",
    "\n",
    "    for i in range(1, max_visit_no + 1):\n",
    "\n",
    "        start_time_1 = time.perf_counter()\n",
    "        print(f\"\\n\\n --->Repeat #{i}:\")\n",
    "        # 1) calculate treatment effects, and base ad ctr, then sum them sup and create ctrs for all ads\n",
    "        start_time = time.perf_counter()\n",
    "        # a) calc TEs and CTRs on s1\n",
    "        calc_split_tes(data, split_no=1, user_visit_no=i, ranks_list=config.ranks_list)\n",
    "        calc_base_ad_split_ctr(data,split_no=1, user_visit_no=i)\n",
    "        calc_split_ctrs(data, split_no=1, user_visit_no=i, ranks_list=config.ranks_list)\n",
    "\n",
    "        # b) calc TEs and CTRs on s2\n",
    "        calc_split_tes(data, split_no=2, user_visit_no=i, ranks_list=config.ranks_list)\n",
    "        calc_base_ad_split_ctr(data,split_no=2, user_visit_no=i)\n",
    "        calc_split_ctrs(data, split_no=2, user_visit_no=i, ranks_list=config.ranks_list)\n",
    "\n",
    "        finish_time = time.perf_counter()\n",
    "        print(f\"Step 1 of repeat {i} finished in {finish_time - start_time} seconds!\")\n",
    "        # 2) determine what ads are chosen\n",
    "        start_time = time.perf_counter()\n",
    "        # find the optimal ads and save them and their corresponding ctr's in the dataframe\n",
    "        # on s1\n",
    "        create_chosen_ad_columns_split(data, split_no=1, user_visit_no=i)\n",
    "        \n",
    "\n",
    "        # on s2\n",
    "        create_chosen_ad_columns_split(data, split_no=2, user_visit_no=i)\n",
    "        finish_time = time.perf_counter()\n",
    "        print(f\"Step 2 of repeat {i} finished in {finish_time - start_time} seconds!\")\n",
    "        # 3) Calculate actual tes and ctrs for the chosen ads\n",
    "        # start_time = time.perf_counter()\n",
    "\n",
    "        # calc_base_ad_actual_ctr(data, split_no=1, user_visit_no=i)\n",
    "        # calc_base_ad_actual_ctr(data, split_no=2, user_visit_no=i)\n",
    "        # finish_1 = time.perf_counter()\n",
    "        # print(f\"{finish_1 - start_time} seconds \")\n",
    "        # calc_actual_ctrs_for_chosen_ads(data, split_no=1, user_visit_no=i)\n",
    "        # calc_actual_ctrs_for_chosen_ads(data, split_no=2, user_visit_no=i)\n",
    "        # finish_2 = time.perf_counter()\n",
    "        # print(f\"{finish_2 - finish_1} seconds \")\n",
    "        # finish_time = time.perf_counter()\n",
    "        # print(f\"Step 3 of repeat {i} finished in {finish_time - start_time} seconds!\")\n",
    "        # 4) Update repeats\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        update_repeats_on_main_and_split(data, split_no=1, user_visit_no=i)\n",
    "        update_repeats_on_main_and_split(data, split_no=2, user_visit_no=i)\n",
    "\n",
    "        finish_time = time.perf_counter()\n",
    "        print(f\"Step 4 of repeat {i} finished in {finish_time - start_time} seconds!\")\n",
    "\n",
    "        # 5) Update clicks\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        update_clicks_on_main_and_split(data, split_no=1, user_visit_no=i)\n",
    "        update_clicks_on_main_and_split(data, split_no=2, user_visit_no=i)        \n",
    "\n",
    "        finish_time = time.perf_counter()\n",
    "        print(f\"Step 5 of repeat {i} finished in {finish_time - start_time} seconds!\")\n",
    "        finish_time_1 = time.perf_counter()\n",
    "        print(f\"Repeat {i}  finished in  {finish_time_1 - start_time_1} seconds!\")\n",
    "\n",
    "    finish_time_2 = time.perf_counter()\n",
    "    print(f\"All Repeats finished in {finish_time_2 - start_time_2} seconds!\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(data_chunks):\n",
    "    print(( i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data[data['global_token_new'] <= 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " --->Repeat #1:\n",
      "finished calculating te's for rank 100 in 312.4069133000012 seconds\n",
      "finished calculating te's for rank 100 in 475.5931062000018 seconds\n",
      "Step 1 of repeat 1 finished in 845.9001587999992 seconds!\n",
      "Step 2 of repeat 1 finished in 132.99836380000124 seconds!\n",
      "Step 4 of repeat 1 finished in 1014.5557028999974 seconds!\n",
      "Step 5 of repeat 1 finished in 1228.7148505000005 seconds!\n",
      "Repeat 1  finished in  3222.171019199999 seconds!\n",
      "\n",
      "\n",
      " --->Repeat #2:\n",
      "finished calculating te's for rank 100 in 413.66601979999905 seconds\n",
      "finished calculating te's for rank 100 in 414.59268489999886 seconds\n",
      "Step 1 of repeat 2 finished in 874.5928582000015 seconds!\n",
      "Step 2 of repeat 2 finished in 80.35409509999954 seconds!\n",
      "Step 4 of repeat 2 finished in 611.5970932000018 seconds!\n",
      "Step 5 of repeat 2 finished in 712.3234010999986 seconds!\n",
      "Repeat 2  finished in  2278.8685750000004 seconds!\n",
      "\n",
      "\n",
      " --->Repeat #3:\n",
      "finished calculating te's for rank 100 in 364.07932079999955 seconds\n",
      "finished calculating te's for rank 100 in 395.08502469999803 seconds\n",
      "Step 1 of repeat 3 finished in 798.4365390000021 seconds!\n",
      "Step 2 of repeat 3 finished in 64.13129350000236 seconds!\n",
      "Step 4 of repeat 3 finished in 473.75233769999977 seconds!\n",
      "Step 5 of repeat 3 finished in 584.4427875000001 seconds!\n",
      "Repeat 3  finished in  1920.7641900999988 seconds!\n",
      "\n",
      "\n",
      " --->Repeat #4:\n",
      "finished calculating te's for rank 100 in 354.9936031000034 seconds\n",
      "finished calculating te's for rank 100 in 383.73169770000095 seconds\n",
      "Step 1 of repeat 4 finished in 775.0650094999983 seconds!\n",
      "Step 2 of repeat 4 finished in 53.609849600001326 seconds!\n",
      "Step 4 of repeat 4 finished in 397.40495060000103 seconds!\n",
      "Step 5 of repeat 4 finished in 462.64359909999985 seconds!\n",
      "Repeat 4  finished in  1688.7254143000027 seconds!\n",
      "\n",
      "\n",
      " --->Repeat #5:\n",
      "finished calculating te's for rank 100 in 361.4342629999992 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msimulate_duopoly\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# if __name__ == '__main__':\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#     multiprocessing.freeze_support() \u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#     with multiprocessing.Pool(processes=5) as pool:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#             main_df = pd.concat([main_df, result_df], ignore_index=True)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#         main_df.to_stata(\"..\\\\results\\\\Duopoly Simluation Results.dta\")\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[48], line 23\u001b[0m, in \u001b[0;36msimulate_duopoly\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     20\u001b[0m calc_split_ctrs(data, split_no\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, user_visit_no\u001b[38;5;241m=\u001b[39mi, ranks_list\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mranks_list)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# b) calc TEs and CTRs on s2\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mcalc_split_tes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_visit_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranks_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mranks_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m calc_base_ad_split_ctr(data,split_no\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, user_visit_no\u001b[38;5;241m=\u001b[39mi)\n\u001b[0;32m     25\u001b[0m calc_split_ctrs(data, split_no\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, user_visit_no\u001b[38;5;241m=\u001b[39mi, ranks_list\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mranks_list)\n",
      "Cell \u001b[1;32mIn[44], line 8\u001b[0m, in \u001b[0;36mcalc_split_tes\u001b[1;34m(data, split_no, user_visit_no, ranks_list)\u001b[0m\n\u001b[0;32m      6\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rank \u001b[38;5;129;01min\u001b[39;00m ranks_list:\n\u001b[1;32m----> 8\u001b[0m     X_s \u001b[38;5;241m=\u001b[39m \u001b[43mconstruct_split_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_visit_no\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_visit_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mad_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     X \u001b[38;5;241m=\u001b[39m construct_actual_X(data, split_no, user_visit_no\u001b[38;5;241m=\u001b[39muser_visit_no, ad_rank\u001b[38;5;241m=\u001b[39mrank)\n\u001b[0;32m     10\u001b[0m     var_name_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mte_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrank\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_s\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[33], line 402\u001b[0m, in \u001b[0;36mconstruct_split_X\u001b[1;34m(data, split_no, user_visit_no, ad_rank)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" \u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03mThis function updates the inputs for estimation so the estimates are for all user visits with a specific user_visit_no, and a specific ad_rank.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;124;03mAfter calling this function, you can estimate the treatment effect for ad ad_rank and the subset of data for which user_visit_no = user_visit_no.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;66;03m# Define X variables\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msplit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43msplit_no\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimpression_repeat_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprevious_clicks_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprevious_clicks_all_ads_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimpression_repeat_base_ad_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprevious_clicks_base_ad_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtotal_visits_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s1_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s2_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s3_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s4_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s5_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s6_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s7_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s8_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s9_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s10_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s11_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s12_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s13_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s14_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s15_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s16_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s17_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s18_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s19_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s20_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s21_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s22_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s23_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s24_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s25_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisit_s26_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_1_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_2_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_3_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_4_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_5_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_6_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_7_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_8_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_9_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_10_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_11_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_12_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_13_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_14_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_15_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_16_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_17_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_18_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_19_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_20_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_21_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_22_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_23_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_24_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_25_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub_26_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmobile_s\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;66;03m# remove \"_s\" from column names in X to be able to run the causal forest model\u001b[39;00m\n\u001b[0;32m    414\u001b[0m X\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\pandas\\core\\indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1096\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1097\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\pandas\\core\\indexing.py:1289\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple_same_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\pandas\\core\\indexing.py:955\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(key):\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 955\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mretval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m    958\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m retval\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[1;32mc:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\pandas\\core\\indexing.py:1325\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_slice_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getbool_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;66;03m# an iterable multi-selection\u001b[39;00m\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, MultiIndex)):\n",
      "File \u001b[1;32mc:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\pandas\\core\\indexing.py:1123\u001b[0m, in \u001b[0;36m_LocationIndexer._getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1121\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(labels, key)\n\u001b[0;32m   1122\u001b[0m inds \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\pandas\\core\\generic.py:3948\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   3941\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3942\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   3943\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3946\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3947\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3948\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3949\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   3950\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32mc:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\pandas\\core\\generic.py:3932\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[1;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[0;32m   3924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3925\u001b[0m         axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3926\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m indices\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3927\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   3928\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_range_indexer(indices, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m   3929\u001b[0m     ):\n\u001b[0;32m   3930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 3932\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3933\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3934\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3937\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3938\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\pandas\\core\\internals\\managers.py:963\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[0;32m    960\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    962\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 963\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\pandas\\core\\internals\\managers.py:747\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    740\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    741\u001b[0m         indexer,\n\u001b[0;32m    742\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    743\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    744\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    745\u001b[0m     )\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 747\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    748\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[0;32m    749\u001b[0m             indexer,\n\u001b[0;32m    750\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    751\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    752\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[0;32m    753\u001b[0m             ),\n\u001b[0;32m    754\u001b[0m         )\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    756\u001b[0m     ]\n\u001b[0;32m    758\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    759\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\pandas\\core\\internals\\managers.py:748\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    740\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    741\u001b[0m         indexer,\n\u001b[0;32m    742\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    743\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    744\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    745\u001b[0m     )\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 748\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    756\u001b[0m     ]\n\u001b[0;32m    758\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    759\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:945\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m    942\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m--> 945\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m    952\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m    953\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ma59396\\AppData\\Local\\anaconda3\\envs\\online_ads\\lib\\site-packages\\pandas\\core\\array_algos\\take.py:165\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    162\u001b[0m func(arr, indexer, out, fill_value)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[1;32m--> 165\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "simulate_duopoly(data_sample)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     multiprocessing.freeze_support() \n",
    "#     with multiprocessing.Pool(processes=5) as pool:\n",
    "#         results = pool.map(simulate_duopoly, data_chunks)  # Parallel execution\n",
    "\n",
    "#         main_df = pd.DataFrame()\n",
    "#         for result_df in results: \n",
    "#             main_df = pd.concat([main_df, result_df], ignore_index=True)\n",
    "#         main_df.to_stata(\"..\\\\results\\\\Duopoly Simluation Results.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_actual_X(data, split_no, user_visit_no, ad_rank):\n",
    "    \"\"\" \n",
    "    This function updates the inputs for estimation so the estimates are for all user visits with a specific user_visit_no, and a specific ad_rank.\n",
    "    After calling this function, you can estimate the treatment effect for ad ad_rank and the subset of data for which user_visit_no = user_visit_no.\n",
    "    \"\"\"\n",
    "    # Define X variables\n",
    "    X = data.loc[data['split'] ==split_no, ['impression_repeat', 'previous_clicks', 'previous_clicks_all_ads',\n",
    "        'impression_repeat_base_ad', 'previous_clicks_base_ad', 'total_visits',\n",
    "        'visit_s1', 'visit_s2', 'visit_s3', 'visit_s4', 'visit_s5', 'visit_s6',\n",
    "        'visit_s7', 'visit_s8', 'visit_s9', 'visit_s10', 'visit_s11',\n",
    "        'visit_s12', 'visit_s13', 'visit_s14', 'visit_s15', 'visit_s16',\n",
    "        'visit_s17', 'visit_s18', 'visit_s19', 'visit_s20', 'visit_s21',\n",
    "        'visit_s22', 'visit_s23', 'visit_s24', 'visit_s25', 'visit_s26',\n",
    "        'sub_1', 'sub_2', 'sub_3', 'sub_4', 'sub_5', 'sub_6', 'sub_7', 'sub_8',\n",
    "        'sub_9', 'sub_10', 'sub_11', 'sub_12', 'sub_13', 'sub_14', 'sub_15',\n",
    "        'sub_16', 'sub_17', 'sub_18', 'sub_19', 'sub_20', 'sub_21', 'sub_22',\n",
    "        'sub_23', 'sub_24', 'sub_25', 'sub_26', 'mobile']]\n",
    "\n",
    "\n",
    "    # #################################### this is for fixing the missing variable sub_24, sub_25, sub_26 on the second split when training the model. Remove this when you fix this problem:\n",
    "    # if split_no == 2:\n",
    "    #     X = X.drop(['sub_24', 'sub_25', 'sub_26'], axis=1)\n",
    "\n",
    "    # Construct X variable for the input to the causal forest\n",
    "    # a) construct base ad initial clicks and repeats\n",
    "\n",
    "    base_ad_str = f\"r_{base_ad}\"\n",
    "    X.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), 'impression_repeat_base_ad'] = data[(data['user_visit_no'] == user_visit_no)  & (data['split'] == split_no)][base_ad_str] + 1  # +1 is because r_* shows previous impressions, but impression repeat is the number of repeats (including current one)\n",
    "\n",
    "    base_ad_str = f\"c_{base_ad}\"\n",
    "    X.loc[(data['user_visit_no'] == user_visit_no)  & (data['split'] == split_no), 'previous_clicks_base_ad'] = data[(data['user_visit_no'] == user_visit_no)  & (data['split'] == split_no)][base_ad_str]\n",
    "\n",
    "# b) construct each ad's initial clicks and repeats\n",
    "    str = f\"r_{ad_rank}\"\n",
    "    X.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), 'impression_repeat'] = data[(data['user_visit_no'] == user_visit_no)  & (data['split'] == split_no)][str] + 1  # +1 is because r_* shows previous impressions, but impression repeat is the number of repeats (including current one)\n",
    "    str = f\"c_{ad_rank}\"\n",
    "    X.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), 'previous_clicks'] = data[(data['user_visit_no'] == user_visit_no)  & (data['split'] == split_no)][str]\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_split_tes(data, split_no, user_visit_no, ranks_list):\n",
    "    \"\"\"\n",
    "    This function calculates the treatment effects for the ads with ranks in \"rank_list\" for the subset of DataFrame \"data\" for which the \"user_visit_no\" is a specific number.\n",
    "    The output is saved in columns te_1, ..., te_{max_adv_rank} of the dataframe \"data\"\n",
    "    \"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    for rank in ranks_list:\n",
    "        X_s = construct_split_X(data, split_no, user_visit_no=user_visit_no, ad_rank=rank)\n",
    "        X = construct_actual_X(data, split_no, user_visit_no=user_visit_no, ad_rank=rank)\n",
    "        var_name_split = f\"te_{rank}_s\"\n",
    "        var_name_actual = f\"te_{rank}\"\n",
    "        if (len(data[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)]) > 0):\n",
    "            exec(f\"data.loc[((data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)) , var_name_split] = config.cf_{rank}_s{split_no}.const_marginal_effect(X_s.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)])\")\n",
    "            exec(f\"data.loc[((data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)) , var_name_actual] = config.cf_{rank}.const_marginal_effect(X.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)])\")\n",
    "        # if rank % 10 == 1:\n",
    "        #     print(f\"rank {rank} done!\")\n",
    "    finish_time = time.perf_counter()\n",
    "    print(f\"finished calculating te's for rank {rank} in {finish_time - start_time} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def calc_actual_tes_for_chosen_ads(data, index):\n",
    "#     tes_list =[]\n",
    "#     for chosen_ad_no in range(1, int(data.loc[index, 'num_ads']) + 1):\n",
    "#         # var_name = f\"chosen_ad_te_{chosen_ad_no}\"\n",
    "#         chosen_ad_var = f\"chosen_ad_{chosen_ad_no}\"\n",
    "#         chosen_ad = int(data.at[index, chosen_ad_var])\n",
    "#         X = data.loc[index: index, ['impression_repeat', 'previous_clicks', 'previous_clicks_all_ads',\n",
    "#         'impression_repeat_base_ad', 'previous_clicks_base_ad', 'total_visits',\n",
    "#         'visit_s1', 'visit_s2', 'visit_s3', 'visit_s4', 'visit_s5', 'visit_s6',\n",
    "#         'visit_s7', 'visit_s8', 'visit_s9', 'visit_s10', 'visit_s11',\n",
    "#         'visit_s12', 'visit_s13', 'visit_s14', 'visit_s15', 'visit_s16',\n",
    "#         'visit_s17', 'visit_s18', 'visit_s19', 'visit_s20', 'visit_s21',\n",
    "#         'visit_s22', 'visit_s23', 'visit_s24', 'visit_s25', 'visit_s26',\n",
    "#         'sub_1', 'sub_2', 'sub_3', 'sub_4', 'sub_5', 'sub_6', 'sub_7', 'sub_8',\n",
    "#         'sub_9', 'sub_10', 'sub_11', 'sub_12', 'sub_13', 'sub_14', 'sub_15',\n",
    "#         'sub_16', 'sub_17', 'sub_18', 'sub_19', 'sub_20', 'sub_21', 'sub_22',\n",
    "#         'sub_23', 'sub_24', 'sub_25', 'sub_26', 'mobile']]\n",
    "        \n",
    "#         # #################################### this is for fixing the missing variable sub_24, sub_25, sub_26 on the second split when training the model. Remove this when you fix this problem:\n",
    "#         # if row['split'] == 2:\n",
    "#         #     X = X.drop(['sub_24', 'sub_25', 'sub_26'])\n",
    "\n",
    "#     # a) construct base ad's initial clicks and repeats\n",
    "#         base_ad_str = f\"r_{base_ad}\"\n",
    "#         X['impression_repeat_base_ad'] = data.loc[index, base_ad_str] + 1  # +1 is because r_* shows previous impressions, but impression repeat is the number of repeats (including current one)\n",
    "\n",
    "#         base_ad_str = f\"c_{base_ad}\"\n",
    "#         X['previous_clicks_base_ad'] =data.loc[index, base_ad_str]\n",
    "\n",
    "#     # b) construct chosen ad's initial clicks and repeats\n",
    "#         str = f\"r_{chosen_ad}\"\n",
    "#         X['impression_repeat'] = data.loc[index, str] + 1  # +1 is because r_* shows previous impressions, but impression repeat is the number of repeats (including current one)\n",
    "#         str = f\"c_{chosen_ad}\"\n",
    "#         X['previous_clicks'] = data.loc[index, str]\n",
    "#         if chosen_ad != base_ad:\n",
    "#             exec(f\"tes_list.append(config.cf_{chosen_ad}.const_marginal_effect(X))\")\n",
    "#         else:\n",
    "#             tes_list.append(np.array([[0]]))\n",
    "#     return np.concatenate(tes_list).flatten()\n",
    "\n",
    "\n",
    "def calc_base_ad_split_ctr(data, split_no, user_visit_no):\n",
    "    \"\"\"\n",
    "    This function calculates E(y0|X=x) for the subset of DataFrame \"data\" for which the \"user_visit_no\" is a specific number.\n",
    "    The output is saved in columns y_{base_ad} of the dataframe \"data\"\n",
    "    \"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    # Define X variables (Note that I am not using previous_clicks and i mpression_repeat variables here, because I'm only using base ad repeats and clicks here)\n",
    "    X_s = data[['previous_clicks_all_ads_s',\n",
    "        'impression_repeat_base_ad_s', 'previous_clicks_base_ad_s', 'total_visits_s',\n",
    "        'visit_s1_s', 'visit_s2_s', 'visit_s3_s', 'visit_s4_s', 'visit_s5_s', 'visit_s6_s',\n",
    "        'visit_s7_s', 'visit_s8_s', 'visit_s9_s', 'visit_s10_s', 'visit_s11_s',\n",
    "        'visit_s12_s', 'visit_s13_s', 'visit_s14_s', 'visit_s15_s', 'visit_s16_s',\n",
    "        'visit_s17_s', 'visit_s18_s', 'visit_s19_s', 'visit_s20_s', 'visit_s21_s',\n",
    "        'visit_s22_s', 'visit_s23_s', 'visit_s24_s', 'visit_s25_s', 'visit_s26_s',\n",
    "        'sub_1_s', 'sub_2_s', 'sub_3_s', 'sub_4_s', 'sub_5_s', 'sub_6_s', 'sub_7_s', 'sub_8_s',\n",
    "        'sub_9_s', 'sub_10_s', 'sub_11_s', 'sub_12_s', 'sub_13_s', 'sub_14_s', 'sub_15_s',\n",
    "        'sub_16_s', 'sub_17_s', 'sub_18_s', 'sub_19_s', 'sub_20_s', 'sub_21_s', 'sub_22_s',\n",
    "        'sub_23_s', 'sub_24_s', 'sub_25_s', 'sub_26_s', 'mobile_s']]\n",
    "    \n",
    "\n",
    "\n",
    "    # remove \"_s\" from column names in X to be able to run the causal forest model\n",
    "    X_s.columns = X_s.columns.str[:-2]\n",
    "\n",
    "\n",
    "    X = data[['previous_clicks_all_ads',\n",
    "        'impression_repeat_base_ad', 'previous_clicks_base_ad', 'total_visits',\n",
    "        'visit_s1', 'visit_s2', 'visit_s3', 'visit_s4', 'visit_s5', 'visit_s6',\n",
    "        'visit_s7', 'visit_s8', 'visit_s9', 'visit_s10', 'visit_s11',\n",
    "        'visit_s12', 'visit_s13', 'visit_s14', 'visit_s15', 'visit_s16',\n",
    "        'visit_s17', 'visit_s18', 'visit_s19', 'visit_s20', 'visit_s21',\n",
    "        'visit_s22', 'visit_s23', 'visit_s24', 'visit_s25', 'visit_s26',\n",
    "        'sub_1', 'sub_2', 'sub_3', 'sub_4', 'sub_5', 'sub_6', 'sub_7', 'sub_8',\n",
    "        'sub_9', 'sub_10', 'sub_11', 'sub_12', 'sub_13', 'sub_14', 'sub_15',\n",
    "        'sub_16', 'sub_17', 'sub_18', 'sub_19', 'sub_20', 'sub_21', 'sub_22',\n",
    "        'sub_23', 'sub_24', 'sub_25', 'sub_26', 'mobile']]\n",
    "    \n",
    "\n",
    "    # #################################### this is for fixing the missing variable sub_24, sub_25, sub_26 on the second split when training the model. Remove this when you fix this problem:\n",
    "    # if (split_no == 2):\n",
    "    #     X = X.drop(['sub_24', 'sub_25', 'sub_26'], axis=1) \n",
    "\n",
    "    var_name_split = f\"y_{base_ad}_s\"\n",
    "    var_name_actual = f\"y_{base_ad}\"\n",
    "\n",
    "    if (len(data[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)]) > 0):\n",
    "        data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), var_name_split] = config.base_ad_y_model.predict(X_s.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)])\n",
    "        data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), var_name_actual] = config.base_ad_y_model.predict(X.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)])\n",
    "    finish_time = time.perf_counter()\n",
    "    # print(f\"finished calculating y0 in {finish_time - start_time} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "def calc_split_ctrs(data, split_no, user_visit_no, ranks_list):\n",
    "    \"\"\"\n",
    "    This function calculates the click rates of all ads for the subset of DataFrame \"data\" for which the \"user_visit_no\" is a specific number by adding y_{base_ad} and treatment effects.\n",
    "    The output is saved in columns y_1, ..., y_{max_adv_rank} of the dataframe \"data\"\n",
    "    \"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    for rank in ranks_list:\n",
    "        y_var_name_split = f'y_{rank}_s'\n",
    "        te_var_name_split = f'te_{rank}_s'\n",
    "        y_base_ad_split = f'y_{base_ad}_s'\n",
    "        y_var_name_actual = f'y_{rank}'\n",
    "        te_var_name_actual = f'te_{rank}'\n",
    "        y_base_ad_actual = f'y_{base_ad}'\n",
    "        if (len(data[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)]) > 0):\n",
    "            # calc ctr for split data\n",
    "            data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), y_var_name_split] = data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), te_var_name_split] + data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), y_base_ad_split]\n",
    "            # set y_{rank} to 0 if it is negative\n",
    "            data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), y_var_name_split] = data.loc[data['user_visit_no'] == user_visit_no, y_var_name_split].apply(lambda x: max(x, 0))\n",
    "            # calc ctr for actual data\n",
    "            data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), y_var_name_actual] = data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), te_var_name_actual] + data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), y_base_ad_actual]\n",
    "            # set y_{rank} to 0 if it is negative\n",
    "            data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), y_var_name_actual] = data.loc[data['user_visit_no'] == user_visit_no, y_var_name_actual].apply(lambda x: max(x, 0))\n",
    "    finish_time = time.perf_counter()\n",
    "    # print(f\"finished calculating y_i's in {finish_time - start_time} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_chosen_split_ad_vars(data):\n",
    "    \"\"\"\n",
    "    This functions initializes three sets of variable in the dataframe \"data\":\n",
    "    1) chosen_ad_{ad}: shows the rank of the the top {ad} chosen ad, ex: chosen_ad_1 is the rank of the top ad chosen to be shown\n",
    "    2)chosen_ad_y_{ad}: shows the corresponding treatment effect of that ad\n",
    "    Initially, all these columns are NaN\n",
    "    3) num_ads:  number of ads to be shown (currently nan)\n",
    "\n",
    "    Inputs:\n",
    "    - data: the dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    for ad in range(1, config.max_ads_per_page + 1):\n",
    "        var_name = f\"chosen_ad_{ad}\"\n",
    "        data.loc[:, var_name] = np.nan\n",
    "\n",
    "\n",
    "    for ad in range(1, config.max_ads_per_page + 1):\n",
    "        var_name = f\"chosen_ad_y_{ad}_s\" \n",
    "        data.loc[:, var_name] = np.nan\n",
    "\n",
    "\n",
    "    for ad in range(1, config.max_ads_per_page + 1):\n",
    "        var_name = f\"chosen_ad_y_{ad}\" \n",
    "        data.loc[:, var_name] = np.nan\n",
    "\n",
    "    for ad in range(1, config.max_ads_per_page + 1):\n",
    "        var_name = f\"chosen_ad_te_{ad}\" \n",
    "        data.loc[:, var_name] = np.nan\n",
    "\n",
    "    for ad in range(1, config.max_ads_per_page + 1):\n",
    "        var_name = f\"chosen_ad_click_dummy_{ad}\"\n",
    "        data.loc[:, var_name] = np.nan\n",
    "    data.loc[:, 'num_ads'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This function is the same for split and non-split\n",
    "def find_optimal_split_ads(row, y_cols):\n",
    "    \"\"\"\n",
    "    This functions calculates optimal ads (based on highest treatment effects) to be shown to the impression in each row. based on the calculated treatment effects y_i s\n",
    "    Inputs: \n",
    "        - row: the row of the dataframe that it is applied to\n",
    "        it has to include indices y_cols and \"ads_on_page\" (determines how many ads to choose)\n",
    "    \n",
    "    Returns: \n",
    "        - chosen_ads: a list of ads to be shown\n",
    "        - chosen_ad_ys: a list of the corresponding treatment effects\n",
    "    \"\"\"\n",
    "\n",
    "    chosen_ad_ys_actual = []\n",
    "    # sort the values by the value of the criteria\n",
    "    sorted_ads = row[y_cols].sort_values(ascending=False).index.to_list()\n",
    "    l = min(row['ads_on_page'], config.max_ads_per_page)    # number of ads to be shown on each visit\n",
    "    chosen_ads = sorted_ads[0 : l]\n",
    "    # creates a list of chosen ad ranks\n",
    "    chosen_ads = [int(element[2: -2]) for element in chosen_ads] # this will turn y_25_s into 25!\n",
    "    chosen_ad_ys_split = row[y_cols].sort_values(ascending=False).values[0:l]\n",
    "    for chosen_ad in chosen_ads:\n",
    "        y_var_name = f\"y_{chosen_ad}\"\n",
    "        chosen_ad_ys_actual.append(row[y_var_name])\n",
    "\n",
    "    return chosen_ads, chosen_ad_ys_split, chosen_ad_ys_actual\n",
    "\n",
    "\n",
    "\n",
    "def create_chosen_ad_columns_split(data, split_no, user_visit_no):\n",
    "    \"\"\"\n",
    "    This function finds the optimal ads for the subsection of \"data\" for which user_visit_no == user_visit_no\n",
    "    The chosen ads and their corresponding click rates are saved in 'chosen_ad_{ad}' and 'chosen_ad_y_{ad}'\n",
    "    \"\"\"\n",
    "    # select treatment effect columns\n",
    "    # te_cols = data.loc[0: 1, :].filter(regex=\"^te_\", axis=1).columns\n",
    "    # select ctr columns:\n",
    "    # y_cols = data.loc[0: 1, :].filter(regex=\"^y_\", axis=1).columns\n",
    "    y_cols = data.columns[data.columns.str.match(r\"^y_.*_s$\")]\n",
    "\n",
    "    for index, row in data[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)].iterrows():\n",
    "        \n",
    "        chosen_ads, chosen_ad_ys_split, chosen_ad_ys_actual = find_optimal_split_ads(row, y_cols)\n",
    "        chosen_ads = [int(element) for element in chosen_ads]\n",
    "        l = len(chosen_ads)\n",
    "        last_chosen_ad_name = f\"chosen_ad_{l}\"\n",
    "        # last_chosen_ad_te_name = f\"chosen_ad_te_{l}\"\n",
    "        last_chosen_ad_y_name_split = f\"chosen_ad_y_{l}_s\"\n",
    "        last_chosen_ad_y_name_actual = f\"chosen_ad_y_{l}\"\n",
    "        data.loc[index, 'chosen_ad_1': last_chosen_ad_name] = chosen_ads\n",
    "        data.loc[index, 'chosen_ad_y_1_s' : last_chosen_ad_y_name_split] = chosen_ad_ys_split\n",
    "        data.loc[index, 'chosen_ad_y_1' : last_chosen_ad_y_name_actual] = chosen_ad_ys_actual\n",
    "        data.at[index, 'num_ads'] = int(l)\n",
    "        # if index % 10000 == 0:\n",
    "        #     print(f\"index {index} done!\")\n",
    "\n",
    "        \n",
    "def calc_base_ad_actual_ctr(data, split_no, user_visit_no):\n",
    "    \"\"\"\n",
    "    This function calculates E(y0|X=x) for the subset of DataFrame \"data\" for which the \"user_visit_no\" is a specific number.\n",
    "    The output is saved in columns y_{base_ad} of the dataframe \"data\"\n",
    "    \"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    # Define X variables (Note that I am not using previous_clicks and i mpression_repeat variables here, because I'm only using base ad repeats and clicks here)\n",
    "    X = data[['previous_clicks_all_ads',\n",
    "        'impression_repeat_base_ad', 'previous_clicks_base_ad', 'total_visits',\n",
    "        'visit_s1', 'visit_s2', 'visit_s3', 'visit_s4', 'visit_s5', 'visit_s6',\n",
    "        'visit_s7', 'visit_s8', 'visit_s9', 'visit_s10', 'visit_s11',\n",
    "        'visit_s12', 'visit_s13', 'visit_s14', 'visit_s15', 'visit_s16',\n",
    "        'visit_s17', 'visit_s18', 'visit_s19', 'visit_s20', 'visit_s21',\n",
    "        'visit_s22', 'visit_s23', 'visit_s24', 'visit_s25', 'visit_s26',\n",
    "        'sub_1', 'sub_2', 'sub_3', 'sub_4', 'sub_5', 'sub_6', 'sub_7', 'sub_8',\n",
    "        'sub_9', 'sub_10', 'sub_11', 'sub_12', 'sub_13', 'sub_14', 'sub_15',\n",
    "        'sub_16', 'sub_17', 'sub_18', 'sub_19', 'sub_20', 'sub_21', 'sub_22',\n",
    "        'sub_23', 'sub_24', 'sub_25', 'sub_26', 'mobile']]\n",
    "    \n",
    "\n",
    "    var_name = f\"y_{base_ad}\"\n",
    "    if (len(data[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)]) > 0):\n",
    "        data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), var_name] = config.base_ad_y_model.predict(X.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)])\n",
    "    finish_time = time.perf_counter()\n",
    "    # print(f\"finished calculating y0 in {finish_time - start_time} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calc_actual_ctrs_for_chosen_ads(data, split_no, user_visit_no):\n",
    "    print(\"updated\")\n",
    "    for index, row in (data[(data['split'] == split_no) & (data['user_visit_no'] == user_visit_no)]).iterrows():\n",
    "        # if (index % 100 == 0):\n",
    "        #     print(index)\n",
    "        tes_list =  calc_actual_tes_for_chosen_ads(data, index)\n",
    "        l = len(tes_list)\n",
    "        last_chosen_ad_te_name = f\"chosen_ad_te_{l}\"\n",
    "        data.loc[index, 'chosen_ad_te_1' : last_chosen_ad_te_name] = tes_list\n",
    "        last_chosen_ad_y_name = f\"chosen_ad_y_{l}\"\n",
    "        base_ad_ctr_var = f\"y_{base_ad}\"\n",
    "        data.loc[index, 'chosen_ad_y_1' : last_chosen_ad_y_name] = data.loc[index, 'chosen_ad_te_1' : last_chosen_ad_te_name] + data.loc[index, base_ad_ctr_var]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import modin.pandas as pd\n",
    "import pandas as pd\n",
    "from econml.dml import CausalForestDML\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.linear_model import Lasso, LassoCV, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV\n",
    "from sklearn.base import BaseEstimator\n",
    "from econml.sklearn_extensions.model_selection import GridSearchCVList\n",
    "import time\n",
    "import joblib\n",
    "import pickle\n",
    "import config\n",
    "\n",
    "# set number of cores to use\n",
    "n_jobs = 36\n",
    "base_ad = 50\n",
    "\n",
    "\n",
    "\n",
    "def read_data(data_set_name):\n",
    "    file_name = f\"..\\\\data\\\\{data_set_name}\"\n",
    "    data = pd.read_stata(file_name)\n",
    "    return data\n",
    "\n",
    "\n",
    "def prepare_data(data, base_ad=50, max_ad=100):\n",
    "    # Set base treatment advertiser_rank =0\n",
    "    data.loc[data['advertiser_rank'] == base_ad, 'advertiser_rank'] = 0\n",
    "    # set advertiser_rank = 101 for 100+ ranked advertisers\n",
    "    data.loc[data['advertiser_rank'] > max_ad, 'advertiser_rank'] = (max_ad + 1)\n",
    "\n",
    "def extract_ranks(data):\n",
    "    # extract the list of available advertiser_ranks\n",
    "    ranks_list = data['advertiser_rank'].value_counts().sort_index().index.tolist()\n",
    "    return ranks_list\n",
    "\n",
    "\n",
    "\n",
    "class PropensityModel(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.lr = LogisticRegression(max_iter=2000)\n",
    "\n",
    "    def predict_proba(self, X, X_indices=slice(-27,-1)):\n",
    "        return self.lr.predict_proba(X[:,X_indices])\n",
    "\n",
    "\n",
    "    \n",
    "    # X_indices are the ones that are used for the estimation of the propensity score\n",
    "    def fit(self, X, y, X_indices=slice(-27,-1)):\n",
    "        self.lr.fit(X[:,X_indices], y)\n",
    "        return self\n",
    "\n",
    "\n",
    "# Instantiate propensity_model from the PropensityModel class\n",
    "propensity_model = PropensityModel()\n",
    "\n",
    "\n",
    "# define the Custom Treatment Model class (its exactly the PropensityModel above. However, I had to include it because I ran the initial model with this one):\n",
    "class CustomTreatmentModel(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.lr = LogisticRegression(max_iter=2000)\n",
    "\n",
    "    def predict_proba(self, X, X_indices=slice(-27,-1)):\n",
    "        return self.lr.predict_proba(X[:,X_indices])\n",
    "\n",
    "\n",
    "    \n",
    "    # X_indices are the ones that are used for the estimation of the propensity score\n",
    "    def fit(self, X, y, X_indices=slice(-27,-1)):\n",
    "        self.lr.fit(X[:,X_indices], y)\n",
    "        return self\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    # 'n_estimators': [50, 100, 200],\n",
    "    'n_estimators': [200],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [1000 , 2000, 3000, 5000]\n",
    "}\n",
    "\n",
    "# Define the hyperparameters to search over\n",
    "cf_param_grid = {\n",
    "    # 'n_estimators': [100, 200, 300],\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [1000 , 2000, 3000, 5000],\n",
    "    'max_samples': [0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def define_xyt(data):\n",
    "    # define X\n",
    "    X = data.drop(['publisher_subject', 'advertiser_rank', 'is_clicked', 'event_no', 'prop'], axis=1)\n",
    "    \n",
    "    # define T\n",
    "    T = data['advertiser_rank']\n",
    "    \n",
    "    # define Y\n",
    "    Y = data['is_clicked']\n",
    "    return X, Y, T\n",
    "\n",
    "\n",
    "def m_model_best_estimator(X, Y, n_jobs=30):\n",
    "    start_time = time.perf_counter()\n",
    "    m_model = RandomForestRegressor(verbose=0, n_jobs=n_jobs)\n",
    "    \n",
    "    # Perform grid search cross-validation\n",
    "    grid_search = GridSearchCV(estimator=m_model, param_grid=param_grid, cv=5)\n",
    "    grid_search.fit(X, Y)\n",
    "    \n",
    "    best_params = grid_search.best_params_\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    finish_time = time.perf_counter()\n",
    "    print(f\"finished tuning the M model in {finish_time - start_time} seconds\")\n",
    "    return best_params\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# def causal_forest_estimate(X, Y, T, cf_param_grid):\n",
    "#     # tune the model:\n",
    "#     start_time = time.perf_counter()\n",
    "\n",
    "#     cf.tune(\n",
    "#                 Y=Y,\n",
    "#                 T=T,\n",
    "#                 X=X,\n",
    "#                 params=cf_param_grid)\n",
    "    \n",
    "#     finish_time = time.perf_counter()\n",
    "#     print(f\"finished tuning the model in {finish_time - start_time} seconds\")\n",
    "\n",
    "#     # fit the model using tuned parameters:\n",
    "#     start_time = time.perf_counter()\n",
    "    \n",
    "#     cf.fit(Y=Y, T=T, X=X, inference=\"blb\", cache_values=True)\n",
    "    \n",
    "#     finish_time = time.perf_counter()\n",
    "#     print(f\"finished fitting the model in {finish_time - start_time} seconds\")\n",
    "#     return cf\n",
    "\n",
    "  \n",
    "    \n",
    "###########################Monopoly Simulation Utility Fuctions########################\n",
    "\n",
    "def construct_X(data, user_visit_no, ad_rank):\n",
    "    \"\"\" \n",
    "    This function updates the inputs for estimation so the estimates are for all user visits with a specific user_visit_no, and a specific ad_rank.\n",
    "    After calling this function, you can estimate the treatment effect for ad ad_rank and the subset of data for which user_visit_no = user_visit_no.\n",
    "    \"\"\"\n",
    "    # Define X variables\n",
    "    X = data[['impression_repeat', 'previous_clicks', 'previous_clicks_all_ads',\n",
    "        'impression_repeat_base_ad', 'previous_clicks_base_ad', 'total_visits',\n",
    "        'visit_s1', 'visit_s2', 'visit_s3', 'visit_s4', 'visit_s5', 'visit_s6',\n",
    "        'visit_s7', 'visit_s8', 'visit_s9', 'visit_s10', 'visit_s11',\n",
    "        'visit_s12', 'visit_s13', 'visit_s14', 'visit_s15', 'visit_s16',\n",
    "        'visit_s17', 'visit_s18', 'visit_s19', 'visit_s20', 'visit_s21',\n",
    "        'visit_s22', 'visit_s23', 'visit_s24', 'visit_s25', 'visit_s26',\n",
    "        'sub_1', 'sub_2', 'sub_3', 'sub_4', 'sub_5', 'sub_6', 'sub_7', 'sub_8',\n",
    "        'sub_9', 'sub_10', 'sub_11', 'sub_12', 'sub_13', 'sub_14', 'sub_15',\n",
    "        'sub_16', 'sub_17', 'sub_18', 'sub_19', 'sub_20', 'sub_21', 'sub_22',\n",
    "        'sub_23', 'sub_24', 'sub_25', 'sub_26', 'mobile']]\n",
    "\n",
    "    # Construct X variable for the input to the causal forest\n",
    "    # a) construct base ad initial clicks and repeats\n",
    "\n",
    "    base_ad_str = f\"r_{base_ad}\"\n",
    "    X.loc[data['user_visit_no'] == user_visit_no, 'impression_repeat_base_ad'] = data[data['user_visit_no'] == user_visit_no][base_ad_str] + 1  # +1 is because r_* shows previous impressions, but impression repeat is the number of repeats (including current one)\n",
    "\n",
    "    base_ad_str = f\"c_{base_ad}\"\n",
    "    X.loc[data['user_visit_no'] == user_visit_no, 'previous_clicks_base_ad'] = data[data['user_visit_no'] == user_visit_no][base_ad_str]\n",
    "\n",
    "# b) construct each ad's initial clicks and repeats\n",
    "    str = f\"r_{ad_rank}\"\n",
    "    X.loc[data['user_visit_no'] == user_visit_no, 'impression_repeat'] = data[data['user_visit_no'] == user_visit_no][str] + 1  # +1 is because r_* shows previous impressions, but impression repeat is the number of repeats (including current one)\n",
    "    str = f\"c_{ad_rank}\"\n",
    "    X.loc[data['user_visit_no'] == user_visit_no, 'previous_clicks'] = data[data['user_visit_no'] == user_visit_no][str]\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def calc_tes(data, user_visit_no, ranks_list):\n",
    "    \"\"\"\n",
    "    This function calculates the treatment effects for the ads with ranks in \"rank_list\" for the subset of DataFrame \"data\" for which the \"user_visit_no\" is a specific number.\n",
    "    The output is saved in columns te_1, ..., te_{max_adv_rank} of the dataframe \"data\"\n",
    "    \"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    for rank in ranks_list:\n",
    "        X = construct_X(data, user_visit_no=user_visit_no, ad_rank=rank)\n",
    "        var_name = f\"te_{rank}\"\n",
    "        exec(f\"data.loc[data['user_visit_no'] == user_visit_no, 'temp'] = config.cf_{rank}.const_marginal_effect(X[data['user_visit_no'] == user_visit_no])\")\n",
    "        data.loc[data['user_visit_no'] == user_visit_no, var_name] = data.loc[data['user_visit_no'] == user_visit_no, 'temp']\n",
    "        # if rank % 10 == 1:\n",
    "        #     print(f\"rank {rank} done!\")\n",
    "    data = data.drop(['temp'], axis=1)\n",
    "    finish_time = time.perf_counter()\n",
    "    print(f\"finished calculating te's for rank {rank} in {finish_time - start_time} seconds\")\n",
    "\n",
    "\n",
    "def calc_base_ad_ctr(data, user_visit_no):\n",
    "    \"\"\"\n",
    "    This function calculates E(y0|X=x) for the subset of DataFrame \"data\" for which the \"user_visit_no\" is a specific number.\n",
    "    The output is saved in columns y_{base_ad} of the dataframe \"data\"\n",
    "    \"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    # Define X variables (Note that I am not using previous_clicks and i mpression_repeat variables here, because I'm only using base ad repeats and clicks here)\n",
    "    X = data[['previous_clicks_all_ads',\n",
    "        'impression_repeat_base_ad', 'previous_clicks_base_ad', 'total_visits',\n",
    "        'visit_s1', 'visit_s2', 'visit_s3', 'visit_s4', 'visit_s5', 'visit_s6',\n",
    "        'visit_s7', 'visit_s8', 'visit_s9', 'visit_s10', 'visit_s11',\n",
    "        'visit_s12', 'visit_s13', 'visit_s14', 'visit_s15', 'visit_s16',\n",
    "        'visit_s17', 'visit_s18', 'visit_s19', 'visit_s20', 'visit_s21',\n",
    "        'visit_s22', 'visit_s23', 'visit_s24', 'visit_s25', 'visit_s26',\n",
    "        'sub_1', 'sub_2', 'sub_3', 'sub_4', 'sub_5', 'sub_6', 'sub_7', 'sub_8',\n",
    "        'sub_9', 'sub_10', 'sub_11', 'sub_12', 'sub_13', 'sub_14', 'sub_15',\n",
    "        'sub_16', 'sub_17', 'sub_18', 'sub_19', 'sub_20', 'sub_21', 'sub_22',\n",
    "        'sub_23', 'sub_24', 'sub_25', 'sub_26', 'mobile']]\n",
    "    var_name = f\"y_{base_ad}\"\n",
    "    data.loc[data['user_visit_no'] == user_visit_no, var_name] = config.base_ad_y_model.predict(X[data['user_visit_no'] == user_visit_no])\n",
    "    finish_time = time.perf_counter()\n",
    "    # print(f\"finished calculating y0 in {finish_time - start_time} seconds\")\n",
    "\n",
    "\n",
    "def calc_ctrs(data, user_visit_no):\n",
    "    \"\"\"\n",
    "    This function calculates the click rates of all ads for the subset of DataFrame \"data\" for which the \"user_visit_no\" is a specific number by adding y_{base_ad} and treatment effects.\n",
    "    The output is saved in columns y_1, ..., y_{max_adv_rank} of the dataframe \"data\"\n",
    "    \"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    for rank in config.ranks_list:\n",
    "        y_var_name = f'y_{rank}'\n",
    "        te_var_name = f'te_{rank}'\n",
    "        y_base_ad = f'y_{base_ad}'\n",
    "        data.loc[data['user_visit_no'] == user_visit_no, y_var_name] = data.loc[data['user_visit_no'] == user_visit_no, te_var_name] + data.loc[data['user_visit_no'] == user_visit_no, y_base_ad]\n",
    "        # set y_{rank} to 0 if it is negative\n",
    "        data.loc[data['user_visit_no'] == user_visit_no, y_var_name] = data.loc[data['user_visit_no'] == user_visit_no, y_var_name].apply(lambda x: max(x, 0))\n",
    "    finish_time = time.perf_counter()\n",
    "    # print(f\"finished calculating y_i's in {finish_time - start_time} seconds\")\n",
    "\n",
    "\n",
    "def create_chosen_ad_vars(data):\n",
    "    \"\"\"\n",
    "    This functions initializes three sets of variable in the dataframe \"data\":\n",
    "    1) chosen_ad_{ad}: shows the rank of the the top {ad} chosen ad, ex: chosen_ad_1 is the rank of the top ad chosen to be shown\n",
    "    2)chosen_ad_y_{ad}: shows the corresponding treatment effect of that ad\n",
    "    Initially, all these columns are NaN\n",
    "    3) num_ads:  number of ads to be shown (currently nan)\n",
    "\n",
    "    Inputs:\n",
    "    - data: the dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    for ad in range(1, config.max_ads_per_page + 1):\n",
    "        var_name1 = f\"chosen_ad_{ad}\"\n",
    "        data.loc[:, var_name1] = np.nan\n",
    "\n",
    "\n",
    "    for ad in range(1, config.max_ads_per_page + 1):\n",
    "        var_name2 = f\"chosen_ad_y_{ad}\"\n",
    "        data.loc[:, var_name2] = np.nan\n",
    "\n",
    "\n",
    "    for ad in range(1, config.max_ads_per_page + 1):\n",
    "        var_name2 = f\"chosen_ad_click_dummy_{ad}\"\n",
    "        data.loc[:, var_name2] = np.nan\n",
    "    data.loc[:, 'num_ads'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "def find_optimal_ads(row, y_cols):\n",
    "    \"\"\"\n",
    "    This functions calculates optimal ads (based on highest treatment effects) to be shown to the impression in each row. based on the calculated treatment effects y_i s\n",
    "    Inputs: \n",
    "        - row: the row of the dataframe that it is applied to\n",
    "        it has to include indices y_cols and \"ads_on_page\" (determines how many ads to choose)\n",
    "    \n",
    "    Returns: \n",
    "        - chosen_ads: a list of ads to be shown\n",
    "        - chosen_ad_ys: a list of the corresponding treatment effects\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # sort the values by the value of the criteria\n",
    "    sorted_ads = row[y_cols].sort_values(ascending=False).index.to_list()\n",
    "    l = min(row['ads_on_page'], config.max_ads_per_page)    # number of ads to be shown on each visit\n",
    "    chosen_ads = sorted_ads[0 : l]\n",
    "    # creates a list of chosen ad ranks\n",
    "    chosen_ads = [int(element.strip(\"y_\")) for element in chosen_ads]\n",
    "    chosen_ad_ys = row[y_cols].sort_values(ascending=False).values[0:l]\n",
    "    return chosen_ads, chosen_ad_ys\n",
    "\n",
    "\n",
    "\n",
    "def create_chosen_ad_columns(data, user_visit_no):\n",
    "    \"\"\"\n",
    "    This function finds the optimal ads for the subsection of \"data\" for which user_visit_no == user_visit_no\n",
    "    The chosen ads and their corresponding click rates are saved in 'chosen_ad_{ad}' and 'chosen_ad_y_{ad}'\n",
    "    \"\"\"\n",
    "    # select treatment effect columns\n",
    "    # te_cols = data.loc[0: 1, :].filter(regex=\"^te_\", axis=1).columns\n",
    "    # select ctr columns:\n",
    "    y_cols = data.loc[0: 1, :].filter(regex=\"^y_\", axis=1).columns\n",
    "\n",
    "\n",
    "    for index, row in data[data['user_visit_no'] == user_visit_no].iterrows():\n",
    "        \n",
    "        chosen_ads, chosen_ad_ys = find_optimal_ads(row, y_cols)\n",
    "        chosen_ads = [int(element) for element in chosen_ads]\n",
    "        l = len(chosen_ads)\n",
    "        last_chosen_ad_name = f\"chosen_ad_{l}\"\n",
    "        # last_chosen_ad_te_name = f\"chosen_ad_te_{l}\"\n",
    "        last_chosen_ad_y_name = f\"chosen_ad_y_{l}\"\n",
    "        data.loc[index, 'chosen_ad_1': last_chosen_ad_name] = chosen_ads\n",
    "        data.loc[index, 'chosen_ad_y_1' : last_chosen_ad_y_name] = chosen_ad_ys\n",
    "        data.at[index, 'num_ads'] = int(l)\n",
    "        # if index % 10000 == 0:\n",
    "        #     print(f\"index {index} done!\")\n",
    "\n",
    "\n",
    "\n",
    "def update_repeats(data, user_visit_no):\n",
    "    \"\"\"\n",
    "    This function updates the number of previous impression on data after user visit number user_visit_no.\n",
    "    For example, after a user visits a page for the first time, and observes optimal ads (say ads 2, 5, 10), the initial impressions for all subsequent visits of that user, the number of previous impressions on ads 2, 5, 10 increases by 1. \n",
    "    \"\"\"\n",
    "    for index, row in data[data['user_visit_no'] == user_visit_no].iterrows():\n",
    "        for chosen_ad_no in range(1, int(row['num_ads']) + 1):\n",
    "            var_name = f\"chosen_ad_{chosen_ad_no}\"\n",
    "            chosen_ad = int(row[var_name])\n",
    "            col_name = f'r_{chosen_ad}'\n",
    "            data.loc[((data['global_token_new'] == row['global_token_new']) & (data['user_visit_no'] > row['user_visit_no'])), col_name] = row[col_name] + 1\n",
    "        # if index % 10000 == 0:\n",
    "        #     print(f\"index {index} done!\")\n",
    "\n",
    "\n",
    "def update_clicks(data, user_visit_no):\n",
    "    \"\"\"\n",
    "    This function updates the number of previous clicks on data after user visit number user_visit_no.\n",
    "    For example, after a user visits a page for the first time, and clicks on ad 5, c_5 increases by 1 for all subsequent user impressions. \n",
    "    It also updates the column \"previous_clicks_all_ads\"\n",
    "    \"\"\"\n",
    "\n",
    "    for index, row in data[data['user_visit_no'] == user_visit_no].iterrows():\n",
    "        total_clicks_on_impression = 0\n",
    "        for chosen_ad_no in range(1, int(row['num_ads']) + 1):\n",
    "            var_name = f\"chosen_ad_{chosen_ad_no}\"\n",
    "            chosen_ad = int(row[var_name])\n",
    "            ctr_var = f'y_{chosen_ad}'\n",
    "            col_name = f'c_{chosen_ad}' # the column name to be updated (if ad 5 is clicked on, c_5 will increase by 1 for all subsequent impressions)\n",
    "            click_dummy_var =f'chosen_ad_click_dummy_{chosen_ad_no}'\n",
    "            rand_click = np.random.rand()   # a random number simulating user's click. User will click if rand_click < y_{chosen_ad}\n",
    "            data.loc[index, click_dummy_var] = int(rand_click <= row[ctr_var])\n",
    "            total_clicks_on_impression += data.loc[index, click_dummy_var]\n",
    "            data.loc[((data['global_token_new'] == row['global_token_new']) & (data['user_visit_no'] > row['user_visit_no'])), col_name] = int(row[col_name] + data.loc[index, click_dummy_var])\n",
    "        data.loc[((data['global_token_new'] == row['global_token_new']) & (data['user_visit_no'] > row['user_visit_no'])), 'previous_clicks_all_ads'] = int(row['previous_clicks_all_ads'] + total_clicks_on_impression)\n",
    "        # if index % 10000 == 0:\n",
    "        #     print(f\"index {index} done!\")    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def create_actual_ctr_vars(data_s):\n",
    "#     \"\"\"\n",
    "#     This functions initializes a set of variable in the split dataframe \"data_s\":\n",
    "#     2)chosen_ad_y_{ad}_actual: shows the ctr of each chosen ad\n",
    "\n",
    "\n",
    "#     Inputs:\n",
    "#     - data: the dataframe\n",
    "\n",
    "#     \"\"\"\n",
    "#     for ad in range(1, config.max_ads_per_page + 1):\n",
    "#         var_name1 = f\"chosen_ad_{ad}\"\n",
    "#         data_s.loc[:, var_name1] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########################Duopoly Simulation Utility Fuctions########################\n",
    "\n",
    "\n",
    "\n",
    "def construct_split_X(data, split_no, user_visit_no, ad_rank):\n",
    "    \"\"\" \n",
    "    This function updates the inputs for estimation so the estimates are for all user visits with a specific user_visit_no, and a specific ad_rank.\n",
    "    After calling this function, you can estimate the treatment effect for ad ad_rank and the subset of data for which user_visit_no = user_visit_no.\n",
    "    \"\"\"\n",
    "    # Define X variables\n",
    "    X = data.loc[data['split'] ==split_no, ['impression_repeat_s', 'previous_clicks_s', 'previous_clicks_all_ads_s',\n",
    "        'impression_repeat_base_ad_s', 'previous_clicks_base_ad_s', 'total_visits_s',\n",
    "        'visit_s1_s', 'visit_s2_s', 'visit_s3_s', 'visit_s4_s', 'visit_s5_s', 'visit_s6_s',\n",
    "        'visit_s7_s', 'visit_s8_s', 'visit_s9_s', 'visit_s10_s', 'visit_s11_s',\n",
    "        'visit_s12_s', 'visit_s13_s', 'visit_s14_s', 'visit_s15_s', 'visit_s16_s',\n",
    "        'visit_s17_s', 'visit_s18_s', 'visit_s19_s', 'visit_s20_s', 'visit_s21_s',\n",
    "        'visit_s22_s', 'visit_s23_s', 'visit_s24_s', 'visit_s25_s', 'visit_s26_s',\n",
    "        'sub_1_s', 'sub_2_s', 'sub_3_s', 'sub_4_s', 'sub_5_s', 'sub_6_s', 'sub_7_s', 'sub_8_s',\n",
    "        'sub_9_s', 'sub_10_s', 'sub_11_s', 'sub_12_s', 'sub_13_s', 'sub_14_s', 'sub_15_s',\n",
    "        'sub_16_s', 'sub_17_s', 'sub_18_s', 'sub_19_s', 'sub_20_s', 'sub_21_s', 'sub_22_s',\n",
    "        'sub_23_s', 'sub_24_s', 'sub_25_s', 'sub_26_s', 'mobile_s']]\n",
    "    # remove \"_s\" from column names in X to be able to run the causal forest model\n",
    "    X.columns = X.columns.str[:-2]\n",
    "\n",
    "    #################################### this is for fixing the missing variable sub_24, sub_25, sub_26 on the second split when training the model. Remove this when you fix this problem:\n",
    "    if split_no == 2:\n",
    "        X = X.drop(['sub_24', 'sub_25', 'sub_26'], axis=1)\n",
    "\n",
    "    # Construct X variable for the input to the causal forest\n",
    "    # a) construct base ad initial clicks and repeats\n",
    "\n",
    "    base_ad_str = f\"r_{base_ad}_s\"\n",
    "    X.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), 'impression_repeat_base_ad'] = data[(data['user_visit_no'] == user_visit_no)  & (data['split'] == split_no)][base_ad_str] + 1  # +1 is because r_* shows previous impressions, but impression repeat is the number of repeats (including current one)\n",
    "\n",
    "    base_ad_str = f\"c_{base_ad}_s\"\n",
    "    X.loc[(data['user_visit_no'] == user_visit_no)  & (data['split'] == split_no), 'previous_clicks_base_ad'] = data[(data['user_visit_no'] == user_visit_no)  & (data['split'] == split_no)][base_ad_str]\n",
    "\n",
    "# b) construct each ad's initial clicks and repeats\n",
    "    str = f\"r_{ad_rank}_s\"\n",
    "    X.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), 'impression_repeat'] = data[(data['user_visit_no'] == user_visit_no)  & (data['split'] == split_no)][str] + 1  # +1 is because r_* shows previous impressions, but impression repeat is the number of repeats (including current one)\n",
    "    str = f\"c_{ad_rank}_s\"\n",
    "    X.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), 'previous_clicks'] = data[(data['user_visit_no'] == user_visit_no)  & (data['split'] == split_no)][str]\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def calc_split_tes(data, split_no, user_visit_no, ranks_list):\n",
    "    \"\"\"\n",
    "    This function calculates the treatment effects for the ads with ranks in \"rank_list\" for the subset of DataFrame \"data\" for which the \"user_visit_no\" is a specific number.\n",
    "    The output is saved in columns te_1, ..., te_{max_adv_rank} of the dataframe \"data\"\n",
    "    \"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    for rank in ranks_list:\n",
    "        X = construct_split_X(data, split_no, user_visit_no=user_visit_no, ad_rank=rank)\n",
    "        var_name = f\"te_{rank}_s\"\n",
    "        if (len(data[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)]) > 0):\n",
    "            exec(f\"data.loc[((data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)) , var_name] = config.cf_{rank}_s{split_no}.const_marginal_effect(X.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)])\")\n",
    "        # if rank % 10 == 1:\n",
    "        #     print(f\"rank {rank} done!\")\n",
    "    finish_time = time.perf_counter()\n",
    "    print(f\"finished calculating te's for rank {rank} in {finish_time - start_time} seconds\")\n",
    "\n",
    "\n",
    "def calc_base_ad_split_ctr(data, split_no, user_visit_no):\n",
    "    \"\"\"\n",
    "    This function calculates E(y0|X=x) for the subset of DataFrame \"data\" for which the \"user_visit_no\" is a specific number.\n",
    "    The output is saved in columns y_{base_ad} of the dataframe \"data\"\n",
    "    \"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    # Define X variables (Note that I am not using previous_clicks and i mpression_repeat variables here, because I'm only using base ad repeats and clicks here)\n",
    "    X = data[['previous_clicks_all_ads_s',\n",
    "        'impression_repeat_base_ad_s', 'previous_clicks_base_ad_s', 'total_visits_s',\n",
    "        'visit_s1_s', 'visit_s2_s', 'visit_s3_s', 'visit_s4_s', 'visit_s5_s', 'visit_s6_s',\n",
    "        'visit_s7_s', 'visit_s8_s', 'visit_s9_s', 'visit_s10_s', 'visit_s11_s',\n",
    "        'visit_s12_s', 'visit_s13_s', 'visit_s14_s', 'visit_s15_s', 'visit_s16_s',\n",
    "        'visit_s17_s', 'visit_s18_s', 'visit_s19_s', 'visit_s20_s', 'visit_s21_s',\n",
    "        'visit_s22_s', 'visit_s23_s', 'visit_s24_s', 'visit_s25_s', 'visit_s26_s',\n",
    "        'sub_1_s', 'sub_2_s', 'sub_3_s', 'sub_4_s', 'sub_5_s', 'sub_6_s', 'sub_7_s', 'sub_8_s',\n",
    "        'sub_9_s', 'sub_10_s', 'sub_11_s', 'sub_12_s', 'sub_13_s', 'sub_14_s', 'sub_15_s',\n",
    "        'sub_16_s', 'sub_17_s', 'sub_18_s', 'sub_19_s', 'sub_20_s', 'sub_21_s', 'sub_22_s',\n",
    "        'sub_23_s', 'sub_24_s', 'sub_25_s', 'sub_26_s', 'mobile_s']]\n",
    "    \n",
    "\n",
    "\n",
    "    # remove \"_s\" from column names in X to be able to run the causal forest model\n",
    "    X.columns = X.columns.str[:-2]\n",
    "\n",
    "    # #################################### this is for fixing the missing variable sub_24, sub_25, sub_26 on the second split when training the model. Remove this when you fix this problem:\n",
    "    # if (split_no == 2):\n",
    "    #     X = X.drop(['sub_24', 'sub_25', 'sub_26'], axis=1) \n",
    "\n",
    "    var_name = f\"y_{base_ad}_s\"\n",
    "    if (len(data[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)]) > 0):\n",
    "        data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), var_name] = config.base_ad_y_model.predict(X.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)])\n",
    "    finish_time = time.perf_counter()\n",
    "    # print(f\"finished calculating y0 in {finish_time - start_time} seconds\")\n",
    "\n",
    "\n",
    "def calc_split_ctrs(data, split_no, user_visit_no, ranks_list):\n",
    "    \"\"\"\n",
    "    This function calculates the click rates of all ads for the subset of DataFrame \"data\" for which the \"user_visit_no\" is a specific number by adding y_{base_ad} and treatment effects.\n",
    "    The output is saved in columns y_1, ..., y_{max_adv_rank} of the dataframe \"data\"\n",
    "    \"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    for rank in ranks_list:\n",
    "        y_var_name = f'y_{rank}_s'\n",
    "        te_var_name = f'te_{rank}_s'\n",
    "        y_base_ad = f'y_{base_ad}_s'\n",
    "        if (len(data[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)]) > 0):\n",
    "            data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), y_var_name] = data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), te_var_name] + data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), y_base_ad]\n",
    "        # set y_{rank} to 0 if it is negative\n",
    "            data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), y_var_name] = data.loc[data['user_visit_no'] == user_visit_no, y_var_name].apply(lambda x: max(x, 0))\n",
    "    finish_time = time.perf_counter()\n",
    "    # print(f\"finished calculating y_i's in {finish_time - start_time} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_chosen_split_ad_vars(data):\n",
    "    \"\"\"\n",
    "    This functions initializes three sets of variable in the dataframe \"data\":\n",
    "    1) chosen_ad_{ad}: shows the rank of the the top {ad} chosen ad, ex: chosen_ad_1 is the rank of the top ad chosen to be shown\n",
    "    2)chosen_ad_y_{ad}: shows the corresponding treatment effect of that ad\n",
    "    Initially, all these columns are NaN\n",
    "    3) num_ads:  number of ads to be shown (currently nan)\n",
    "\n",
    "    Inputs:\n",
    "    - data: the dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    for ad in range(1, config.max_ads_per_page + 1):\n",
    "        var_name = f\"chosen_ad_{ad}\"\n",
    "        data.loc[:, var_name] = np.nan\n",
    "\n",
    "\n",
    "    for ad in range(1, config.max_ads_per_page + 1):\n",
    "        var_name = f\"chosen_ad_y_{ad}_s\" \n",
    "        data.loc[:, var_name] = np.nan\n",
    "\n",
    "\n",
    "    for ad in range(1, config.max_ads_per_page + 1):\n",
    "        var_name = f\"chosen_ad_y_{ad}\" \n",
    "        data.loc[:, var_name] = np.nan\n",
    "\n",
    "    for ad in range(1, config.max_ads_per_page + 1):\n",
    "        var_name = f\"chosen_ad_te_{ad}\" \n",
    "        data.loc[:, var_name] = np.nan\n",
    "\n",
    "    for ad in range(1, config.max_ads_per_page + 1):\n",
    "        var_name = f\"chosen_ad_click_dummy_{ad}\"\n",
    "        data.loc[:, var_name] = np.nan\n",
    "    data.loc[:, 'num_ads'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This function is the same for split and non-split\n",
    "def find_optimal_ads(row, y_cols):\n",
    "    \"\"\"\n",
    "    This functions calculates optimal ads (based on highest treatment effects) to be shown to the impression in each row. based on the calculated treatment effects y_i s\n",
    "    Inputs: \n",
    "        - row: the row of the dataframe that it is applied to\n",
    "        it has to include indices y_cols and \"ads_on_page\" (determines how many ads to choose)\n",
    "    \n",
    "    Returns: \n",
    "        - chosen_ads: a list of ads to be shown\n",
    "        - chosen_ad_ys: a list of the corresponding treatment effects\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # sort the values by the value of the criteria\n",
    "    sorted_ads = row[y_cols].sort_values(ascending=False).index.to_list()\n",
    "    l = min(row['ads_on_page'], config.max_ads_per_page)    # number of ads to be shown on each visit\n",
    "    chosen_ads = sorted_ads[0 : l]\n",
    "    # creates a list of chosen ad ranks\n",
    "    chosen_ads = [int(element[2: -2]) for element in chosen_ads] # this will turn y_25_s into 25!\n",
    "    chosen_ad_ys = row[y_cols].sort_values(ascending=False).values[0:l]\n",
    "    return chosen_ads, chosen_ad_ys\n",
    "\n",
    "\n",
    "\n",
    "def create_chosen_ad_columns_split(data, split_no, user_visit_no):\n",
    "    \"\"\"\n",
    "    This function finds the optimal ads for the subsection of \"data\" for which user_visit_no == user_visit_no\n",
    "    The chosen ads and their corresponding click rates are saved in 'chosen_ad_{ad}' and 'chosen_ad_y_{ad}'\n",
    "    \"\"\"\n",
    "    # select treatment effect columns\n",
    "    # te_cols = data.loc[0: 1, :].filter(regex=\"^te_\", axis=1).columns\n",
    "    # select ctr columns:\n",
    "    # y_cols = data.loc[0: 1, :].filter(regex=\"^y_\", axis=1).columns\n",
    "    y_cols = data.columns[data.columns.str.match(r\"^y_.*_s$\")]\n",
    "\n",
    "    for index, row in data[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)].iterrows():\n",
    "        \n",
    "        chosen_ads, chosen_ad_ys = find_optimal_ads(row, y_cols)\n",
    "        chosen_ads = [int(element) for element in chosen_ads]\n",
    "        l = len(chosen_ads)\n",
    "        last_chosen_ad_name = f\"chosen_ad_{l}\"\n",
    "        # last_chosen_ad_te_name = f\"chosen_ad_te_{l}\"\n",
    "        last_chosen_ad_y_name = f\"chosen_ad_y_{l}_s\"\n",
    "        data.loc[index, 'chosen_ad_1': last_chosen_ad_name] = chosen_ads\n",
    "        data.loc[index, 'chosen_ad_y_1_s' : last_chosen_ad_y_name] = chosen_ad_ys\n",
    "        data.at[index, 'num_ads'] = int(l)\n",
    "        # if index % 10000 == 0:\n",
    "        #     print(f\"index {index} done!\")\n",
    "\n",
    "        \n",
    "def calc_base_ad_actual_ctr(data, split_no, user_visit_no):\n",
    "    \"\"\"\n",
    "    This function calculates E(y0|X=x) for the subset of DataFrame \"data\" for which the \"user_visit_no\" is a specific number.\n",
    "    The output is saved in columns y_{base_ad} of the dataframe \"data\"\n",
    "    \"\"\"\n",
    "    start_time = time.perf_counter()\n",
    "    # Define X variables (Note that I am not using previous_clicks and i mpression_repeat variables here, because I'm only using base ad repeats and clicks here)\n",
    "    X = data[['previous_clicks_all_ads',\n",
    "        'impression_repeat_base_ad', 'previous_clicks_base_ad', 'total_visits',\n",
    "        'visit_s1', 'visit_s2', 'visit_s3', 'visit_s4', 'visit_s5', 'visit_s6',\n",
    "        'visit_s7', 'visit_s8', 'visit_s9', 'visit_s10', 'visit_s11',\n",
    "        'visit_s12', 'visit_s13', 'visit_s14', 'visit_s15', 'visit_s16',\n",
    "        'visit_s17', 'visit_s18', 'visit_s19', 'visit_s20', 'visit_s21',\n",
    "        'visit_s22', 'visit_s23', 'visit_s24', 'visit_s25', 'visit_s26',\n",
    "        'sub_1', 'sub_2', 'sub_3', 'sub_4', 'sub_5', 'sub_6', 'sub_7', 'sub_8',\n",
    "        'sub_9', 'sub_10', 'sub_11', 'sub_12', 'sub_13', 'sub_14', 'sub_15',\n",
    "        'sub_16', 'sub_17', 'sub_18', 'sub_19', 'sub_20', 'sub_21', 'sub_22',\n",
    "        'sub_23', 'sub_24', 'sub_25', 'sub_26', 'mobile']]\n",
    "    \n",
    "\n",
    "    var_name = f\"y_{base_ad}\"\n",
    "    if (len(data[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)]) > 0):\n",
    "        data.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no), var_name] = config.base_ad_y_model.predict(X.loc[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)])\n",
    "    finish_time = time.perf_counter()\n",
    "    # print(f\"finished calculating y0 in {finish_time - start_time} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "def calc_actual_tes_for_chosen_ads(data, index):\n",
    "    tes_list =[]\n",
    "    for chosen_ad_no in range(1, int(data.loc[index, 'num_ads']) + 1):\n",
    "        # var_name = f\"chosen_ad_te_{chosen_ad_no}\"\n",
    "        chosen_ad_var = f\"chosen_ad_{chosen_ad_no}\"\n",
    "        chosen_ad = int(data.at[index, chosen_ad_var])\n",
    "        X = data.loc[index: index, ['impression_repeat', 'previous_clicks', 'previous_clicks_all_ads',\n",
    "        'impression_repeat_base_ad', 'previous_clicks_base_ad', 'total_visits',\n",
    "        'visit_s1', 'visit_s2', 'visit_s3', 'visit_s4', 'visit_s5', 'visit_s6',\n",
    "        'visit_s7', 'visit_s8', 'visit_s9', 'visit_s10', 'visit_s11',\n",
    "        'visit_s12', 'visit_s13', 'visit_s14', 'visit_s15', 'visit_s16',\n",
    "        'visit_s17', 'visit_s18', 'visit_s19', 'visit_s20', 'visit_s21',\n",
    "        'visit_s22', 'visit_s23', 'visit_s24', 'visit_s25', 'visit_s26',\n",
    "        'sub_1', 'sub_2', 'sub_3', 'sub_4', 'sub_5', 'sub_6', 'sub_7', 'sub_8',\n",
    "        'sub_9', 'sub_10', 'sub_11', 'sub_12', 'sub_13', 'sub_14', 'sub_15',\n",
    "        'sub_16', 'sub_17', 'sub_18', 'sub_19', 'sub_20', 'sub_21', 'sub_22',\n",
    "        'sub_23', 'sub_24', 'sub_25', 'sub_26', 'mobile']]\n",
    "        \n",
    "        # #################################### this is for fixing the missing variable sub_24, sub_25, sub_26 on the second split when training the model. Remove this when you fix this problem:\n",
    "        # if row['split'] == 2:\n",
    "        #     X = X.drop(['sub_24', 'sub_25', 'sub_26'])\n",
    "\n",
    "    # a) construct base ad's initial clicks and repeats\n",
    "        base_ad_str = f\"r_{base_ad}\"\n",
    "        X['impression_repeat_base_ad'] = data.loc[index, base_ad_str] + 1  # +1 is because r_* shows previous impressions, but impression repeat is the number of repeats (including current one)\n",
    "\n",
    "        base_ad_str = f\"c_{base_ad}\"\n",
    "        X['previous_clicks_base_ad'] =data.loc[index, base_ad_str]\n",
    "\n",
    "    # b) construct chosen ad's initial clicks and repeats\n",
    "        str = f\"r_{chosen_ad}\"\n",
    "        X['impression_repeat'] = data.loc[index, str] + 1  # +1 is because r_* shows previous impressions, but impression repeat is the number of repeats (including current one)\n",
    "        str = f\"c_{chosen_ad}\"\n",
    "        X['previous_clicks'] = data.loc[index, str]\n",
    "        if chosen_ad != base_ad:\n",
    "            exec(f\"tes_list.append(config.cf_{chosen_ad}.const_marginal_effect(X))\")\n",
    "        else:\n",
    "            tes_list.append(np.array([[0]]))\n",
    "    return np.concatenate(tes_list).flatten()\n",
    "\n",
    "\n",
    "\n",
    "def calc_actual_ctrs_for_chosen_ads(data, split_no, user_visit_no):\n",
    "    print(\"updated\")\n",
    "    for index, row in (data[(data['split'] == split_no) & (data['user_visit_no'] == user_visit_no)]).iterrows():\n",
    "        # if (index % 100 == 0):\n",
    "        #     print(index)\n",
    "        tes_list =  calc_actual_tes_for_chosen_ads(data, index)\n",
    "        l = len(tes_list)\n",
    "        last_chosen_ad_te_name = f\"chosen_ad_te_{l}\"\n",
    "        data.loc[index, 'chosen_ad_te_1' : last_chosen_ad_te_name] = tes_list\n",
    "        last_chosen_ad_y_name = f\"chosen_ad_y_{l}\"\n",
    "        base_ad_ctr_var = f\"y_{base_ad}\"\n",
    "        data.loc[index, 'chosen_ad_y_1' : last_chosen_ad_y_name] = data.loc[index, 'chosen_ad_te_1' : last_chosen_ad_te_name] + data.loc[index, base_ad_ctr_var]\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def update_repeats_on_main_and_split(data, split_no, user_visit_no):\n",
    "\n",
    "    \"\"\"\n",
    "    This function updates the number of previous impression on data after user visit number user_visit_no.\n",
    "    For example, after a user visits a page for the first time, and observes optimal ads (say ads 2, 5, 10), the initial impressions for all subsequent visits of that user, the number of previous impressions on ads 2, 5, 10 increases by 1. \n",
    "    \"\"\"\n",
    "    for index, row in data[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)].iterrows():\n",
    "\n",
    "        for chosen_ad_no in range(1, int(row['num_ads']) + 1):\n",
    "            var_name = f\"chosen_ad_{chosen_ad_no}\"\n",
    "            chosen_ad = int(row[var_name])\n",
    "            col_name_main = f'r_{chosen_ad}'\n",
    "            col_name_split = f'r_{chosen_ad}_s'\n",
    "            data.loc[((data['global_token_new'] == row['global_token_new']) & (data['user_visit_no'] > row['user_visit_no'])), col_name_main] = row[col_name_main] + 1 # update actual repeats on all subsequent impressions of the user\n",
    "            data.loc[((data['global_token_new'] == row['global_token_new']) & (data['user_visit_no'] > row['user_visit_no']) & (data['split'] == row['split'])), col_name_split] = row[col_name_split] + 1 # update split repeats on subsequent impressions of the user only if it is on the same split (platform)\n",
    "\n",
    "\n",
    "\n",
    "def update_clicks_on_main_and_split(data, split_no, user_visit_no):\n",
    "    \"\"\"\n",
    "    This function updates the number of previous clicks on data after user visit number user_visit_no.\n",
    "    For example, after a user visits a page for the first time, and clicks on ad 5, c_5 increases by 1 for all subsequent user impressions. \n",
    "    It also updates the column \"previous_clicks_all_ads\"\n",
    "    \"\"\"\n",
    "\n",
    "    for index, row in data[(data['user_visit_no'] == user_visit_no) & (data['split'] == split_no)].iterrows():\n",
    "        total_clicks_on_impression = 0\n",
    "        for chosen_ad_no in range(1, int(row['num_ads']) + 1):\n",
    "            var_name = f\"chosen_ad_{chosen_ad_no}\"\n",
    "            chosen_ad = int(row[var_name])\n",
    "            ctr_var = f'chosen_ad_y_{chosen_ad_no}'\n",
    "            col_name_main = f'c_{chosen_ad}' # the column name to be updated (if ad 5 is clicked on, c_5 will increase by 1 for all subsequent impressions)\n",
    "            col_name_split = f'c_{chosen_ad}_s' # the column name to be updated (if ad 5 is clicked on, c_5_s will increase by 1 for all subsequent impressions)\n",
    "            click_dummy_var =f'chosen_ad_click_dummy_{chosen_ad_no}'\n",
    "            rand_click = np.random.rand()   # a random number simulating user's click. User will click if rand_click < y_{chosen_ad}\n",
    "            # print(data.at[index, ctr_var])\n",
    "            data.loc[index, click_dummy_var] = int(rand_click <= row[ctr_var])\n",
    "            total_clicks_on_impression += data.loc[index, click_dummy_var]\n",
    "            data.loc[((data['global_token_new'] == row['global_token_new']) & (data['user_visit_no'] > row['user_visit_no'])), col_name_main] = int(row[col_name_main] + data.loc[index, click_dummy_var])\n",
    "            data.loc[((data['global_token_new'] == row['global_token_new']) & (data['user_visit_no'] > row['user_visit_no']) & (data['split'] == row['split'])), col_name_split] = int(row[col_name_split] + data.loc[index, click_dummy_var]) # update only if it is on the same split (platform)\n",
    "        data.loc[((data['global_token_new'] == row['global_token_new']) & (data['user_visit_no'] > row['user_visit_no'])), 'previous_clicks_all_ads'] = int(row['previous_clicks_all_ads'] + total_clicks_on_impression)\n",
    "        data.loc[((data['global_token_new'] == row['global_token_new']) & (data['user_visit_no'] > row['user_visit_no']) & (data['split'] == row['split'])), 'previous_clicks_all_ads_s'] = int(row['previous_clicks_all_ads'] + total_clicks_on_impression)  # update only if it is on the same split (platform)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "online_ads",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
